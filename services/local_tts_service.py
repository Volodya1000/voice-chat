import io
import torch
import soundfile as sf
import numpy as np
from typing import List, Optional, Tuple

import librosa  # Ğ´Ğ»Ñ pitch/time-stretch

def _select_device() -> torch.device:
    if torch.cuda.is_available():
        print("ğŸš€ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ CUDA (GPU).")
        return torch.device('cuda')
    else:
        print("ğŸ–¥ï¸ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ CPU.")
        return torch.device('cpu')


class LocalTextToVoiceService:
    """
    Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ TTS (Text-to-Speech) Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ Silero.
    ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ speed, pitch, gain, reverb Ğ¸ Ğ¿Ğ°ÑƒĞ·Ñ‹.
    """

    DEFAULT_LANGUAGE = 'ru'
    DEFAULT_MODEL_ID = 'v4_ru'
    DEFAULT_SAMPLE_RATE = 48000

    def __init__(self,
                 language: str = DEFAULT_LANGUAGE,
                 model_id: str = DEFAULT_MODEL_ID,
                 sample_rate: int = DEFAULT_SAMPLE_RATE):
        self.language = language
        self.model_id = model_id
        self.sample_rate = sample_rate
        self.device = _select_device()
        self.model = None
        self.speakers: List[str] = []
        self._load_model()

    def _load_model(self):
        print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Silero ({self.model_id})...")
        try:
            self.model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-models',
                model='silero_tts',
                language=self.language,
                speaker=self.model_id
            )
            self.model.to(self.device)
            self.speakers = getattr(self.model, "speakers", [self.model_id])
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°. Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ´Ğ¸ĞºÑ‚Ğ¾Ñ€Ñ‹: {self.speakers}")
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")
            self.model = None

    def synthesize_to_bytes(
        self,
        text: str,
        speaker: str = 'aidar',
        speed: float = 1.0,
        pitch_semitones: float = 0.0,
        gain_db: float = 0.0,
        reverb_time: float = 0.0,
        reverb_decay: float = 0.0,
        silence_before: float = 0.0,
        silence_after: float = 0.0
    ) -> bytes:
        """
        Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ñ€ĞµÑ‡Ğ¸ Ğ¸ Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ²ÑĞµÑ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ².
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ WAV Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ±Ğ°Ğ¹Ñ‚Ğ¾Ğ².
        """
        if not self.model:
            raise RuntimeError("TTS Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°")

        if speaker not in self.speakers:
            raise ValueError(f"Ğ“Ğ¾Ğ»Ğ¾Ñ '{speaker}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ: {self.speakers}")

        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾ (numpy float32)
        wav_tensor = self.model.apply_tts(
            text=text,
            speaker=speaker,
            sample_rate=self.sample_rate
        )
        wav = wav_tensor.detach().cpu().numpy().astype(np.float32)

        # -----------------------
        # ĞŸĞ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        # -----------------------
        wav = self._add_silence(wav, silence_before, silence_after)
        wav = self._pitch_shift(wav, pitch_semitones)
        wav = self._time_stretch(wav, speed)
        wav = self._change_volume(wav, gain_db)
        wav = self._add_reverb(wav, reverb_time, reverb_decay)
        wav = self._normalize(wav)

        # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ² WAV Ğ±Ğ°Ğ¹Ñ‚Ñ‹
        buffer = io.BytesIO()
        sf.write(buffer, wav, self.sample_rate, format='WAV')
        buffer.seek(0)
        return buffer.read()

    # -----------------------
    # ĞŸĞ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
    # -----------------------
    def _normalize(self, wav: np.ndarray, target_peak: float = 0.98) -> np.ndarray:
        peak = np.max(np.abs(wav))
        if peak > 0:
            wav = wav * (target_peak / peak)
        return wav.astype(np.float32)

    def _change_volume(self, wav: np.ndarray, db: float) -> np.ndarray:
        factor = 10 ** (db / 20)
        return (wav * factor).astype(np.float32)

    def _time_stretch(self, wav: np.ndarray, speed: float) -> np.ndarray:
        if abs(speed - 1.0) < 1e-6:
            return wav
        return librosa.effects.time_stretch(wav, rate=speed).astype(np.float32)

    def _pitch_shift(self, wav: np.ndarray, n_steps: float) -> np.ndarray:
        if abs(n_steps) < 1e-6:
            return wav
        return librosa.effects.pitch_shift(wav, sr=self.sample_rate, n_steps=n_steps).astype(np.float32)

    def _add_silence(self, wav: np.ndarray, before: float, after: float) -> np.ndarray:
        b = int(round(before * self.sample_rate))
        a = int(round(after * self.sample_rate))
        if b == 0 and a == 0:
            return wav
        silence_before = np.zeros(b, dtype=np.float32)
        silence_after = np.zeros(a, dtype=np.float32)
        return np.concatenate([silence_before, wav, silence_after]).astype(np.float32)

    def _add_reverb(self, wav: np.ndarray, reverb_time: float, decay: float) -> np.ndarray:
        if reverb_time <= 0 or decay <= 0:
            return wav
        n = int(self.sample_rate * reverb_time)
        t = np.arange(n, dtype=np.float32)
        ir = (decay ** (t / (self.sample_rate * reverb_time))).astype(np.float32)
        ir /= (np.sum(np.abs(ir)) + 1e-9)
        convolved = np.convolve(wav, ir, mode='full')[:len(wav)]
        out = wav + convolved * 0.7
        out /= max(1.0, np.max(np.abs(out)) + 1e-9)
        return out.astype(np.float32)
